from copy import deepcopy
from typing import List, Type

from .dataset import Dataset, DatasetGenerator, DataSplittingConfig, Epochs
from .load_data import Raw, RawDataLoader
from .preprocessor import PreprocessBase
from .training import ModelHolder, Trainer, TrainingOption, TrainingPlanHolder
from .utils import validate_issubclass, validate_list_type, validate_type


class Study:
    """Class for storing required info a study.

    Attributes:
        loaded_data_list: list[:class:`XBrainLab.load_data.Raw`].
            The raw data result loaded by :class:`XBrainLab.load_data.RawDataLoader`.
        preprocessed_data_list: list[:class:`XBrainLab.load_data.Raw`].
            The preprocessed data result generated by
                sequences of :class:`XBrainLab.preprocessor.base.PreprocessBase`.
        epoch_data: :class:`XBrainLab.dataset.Epochs` or None.
            The epoch data generated from list of :class:`XBrainLab.load_data.Raw`.
        datasets: list[:class:`XBrainLab.dataset.Dataset`].
            The datasets generated from :class:`XBrainLab.dataset.DatasetGenerator`.
        model_holder: :class:`XBrainLab.training.ModelHolder` or None.
            The model with parameters.
        training_option: :class:`XBrainLab.training.TrainingOption` or None.
            The training option.
        trainer: :class:`XBrainLab.training.Trainer` or None.
            The model trainer.
    """
    def __init__(self) -> None:
         # raw data
        self.loaded_data_list = []
        self.preprocessed_data_list = []
        self.epoch_data = None
        # datasets
        self.datasets = []
        # training
        self.model_holder = None
        self.training_option = None
        self.trainer = None
        # visulaization
        self.saliency_params = None

    # step 1 - load data
    def get_raw_data_loader(self) -> RawDataLoader:
        """Return a new :class:`XBrainLab.load_data.RawDataLoader` instance.

        Helper function to get loader for loading raw data.
        """
        return RawDataLoader()

    def set_loaded_data_list(
        self,
        loaded_data_list: List[Raw],
        force_update: bool = False
    ) -> None:
        """Set loaded data list.

        Args:
            loaded_data_list: The raw data result loaded by
                              :class:`XBrainLab.load_data.RawDataLoader`.
            force_update: Whether to force override and
                          clear the data of following steps.
        """
        validate_list_type(loaded_data_list, Raw, 'loaded_data_list')
        self.clean_raw_data(force_update)
        self.set_preprocessed_data_list(
            preprocessed_data_list=deepcopy(loaded_data_list),
            force_update=force_update
        )
        self.loaded_data_list = loaded_data_list

    # step 2 - preprocess
    def set_preprocessed_data_list(
        self,
        preprocessed_data_list: List[Raw],
        force_update: bool = False
    ) -> None:
        """Set preprocessed data list.

        Args:
            preprocessed_data_list: The preprocessed data result generated by
                sequences of :class:`XBrainLab.preprocessor.base.PreprocessBase`.
            force_update: Whether to force override and
                          clear the data of following steps.
        """
        validate_list_type(preprocessed_data_list, Raw, 'preprocessed_data_list')
        self.clean_datasets(force_update=force_update)

        self.preprocessed_data_list = preprocessed_data_list
        for preprocessed_data in preprocessed_data_list:
            # skip generating epoch data if data is still raw data
            if preprocessed_data.is_raw():
                self.epoch_data = None
                return
        self.epoch_data = Epochs(preprocessed_data_list)

    def reset_preprocess(self, force_update=False) -> None:
        """Discard all preprocessed data and reset to loaded data.

        Args:
            force_update: Whether to force override and
                          clear the data of following steps.
        """
        if self.loaded_data_list:
            self.set_preprocessed_data_list(
                deepcopy(self.loaded_data_list), force_update=force_update
            )

    def preprocess(self, preprocessor: Type[PreprocessBase], **kargs: dict) -> None:
        """Preprocess data.

        Args:
            preprocessor: The preprocessor class.
                          Should be subclass of
                          :class:`XBrainLab.preprocessor.base.PreprocessBase`.
            **kargs: The parameters for preprocessor.
        """
        validate_issubclass(preprocessor, PreprocessBase, 'preprocessor')
        preprocessor = preprocessor(self.preprocessed_data_list)
        preprocessor.check_data()
        preprocessed_data_list = preprocessor.data_preprocess(**kargs)
        self.set_preprocessed_data_list(preprocessed_data_list)

    # step 3 - split data for training
    def get_datasets_generator(self, config: DataSplittingConfig) -> DatasetGenerator:
        """Return a new :class:`XBrainLab.dataset.DatasetGenerator` instance.

        Helper function to get generator for generating datasets.
        """
        validate_type(config, DataSplittingConfig, "config")
        return DatasetGenerator(self.epoch_data, config)

    def set_datasets(
        self,
        datasets: List[Dataset],
        force_update: bool = False
    ) -> None:
        """Set generated datasets for training.

        Args:
            datasets:
               The datasets generated from :class:`XBrainLab.dataset.DatasetGenerator`.
            force_update:
               Whether to force override and clear the data of following steps.
        """
        validate_list_type(datasets, Dataset, 'datasets')
        self.clean_datasets(force_update=force_update)
        self.datasets = datasets

    # step 4 - training config
    def set_training_option(
        self,
        training_option: TrainingOption,
        force_update: bool = False
    ) -> None:
        """Set training option.

        Args:
            training_option: The training option.
            force_update: Whether to force override and
                          clear the data of following steps.
        """
        validate_type(training_option, TrainingOption, 'training_option')
        self.clean_trainer(force_update=force_update)
        self.training_option = training_option

    def set_model_holder(
        self,
        model_holder: ModelHolder,
        force_update: bool = False
    ) -> None:
        """Set model holder.

        Args:
            model_holder: The model with parameters.
            force_update: Whether to force override and
                          clear the data of following steps.
        """
        validate_type(model_holder, ModelHolder, 'model_holder')
        self.clean_trainer(force_update=force_update)
        self.model_holder = model_holder

    def generate_plan(self, force_update: bool = False) -> None:
        """Generate training plan.

        Helper function to
        generate :class:`XBrainLab.training.TrainingPlanHolder`
        from model holder, datasets and training option, and then
        generate :class:`XBrainLab.training.Trainer` from training plan holders.

        Args:
            force_update: Whether to force override and
                          clear the data of following steps.

        Raises:
            ValueError: If no valid dataset, training option or
                        model holder has been generated.
        """
        self.clean_trainer(force_update=force_update)

        if not self.datasets:
            raise ValueError('No valid dataset is generated')
        if not self.training_option:
            raise ValueError('No valid training option is generated')
        if not self.model_holder:
            raise ValueError('No valid model holder is generated')

        training_plan_holders = []
        option = self.training_option
        model_holder = self.model_holder
        datasets = self.datasets
        training_plan_holders = [
            TrainingPlanHolder(model_holder, dataset, option, self.saliency_params)
            for dataset in datasets
        ]
        self.trainer = Trainer(training_plan_holders)

    # step 5 - training
    def train(self, interact: bool = False) -> None:
        """Start training.

        Args:
            interact: Whether to run in interactive mode.
                      If True, the training will run in a new thread.

        Raises:
            ValueError: If no valid trainer has been generated.
        """
        if not self.trainer:
            raise ValueError('No valid trainer is generated')

        self.trainer.run(interact=interact)

    def stop_training(self) -> None:
        """Stop training.

        Raises:
            ValueError: If no valid trainer has been generated.
        """
        if not self.trainer:
            raise ValueError('No valid trainer is generated')
        self.trainer.set_interrupt()

    def is_training(self) -> bool:
        """Return whether training is running.

        Raises:
            ValueError: If no valid trainer has been generated.
        """
        if self.trainer:
            return self.trainer.is_running()
        return False

    # step 6 - evaluation
    def export_output_csv(self, filepath: str, plan_name: str, real_plan_name: str):
        """Export model inference output to csv file.

        Helper function to export model inference output to csv file.

        Args:
            filepath: The output csv file path.
            plan_name: The name of training plan.
            real_plan_name: The name of real plan under training plan.

        Raises:
            ValueError: If no valid training plan or real plan is generated.
        """
        if not self.trainer:
            raise ValueError("No valid training plan is generated")
        plan = self.trainer.get_real_training_plan(plan_name, real_plan_name)
        record = plan.get_eval_record()
        if not record:
            raise ValueError(
                'No evaluation record for this training plan'
            )
        record.export_csv(filepath)

    # step 7 - visualization
    def set_channels(self, chs: List[str], positions: List[tuple]) -> None:
        """Set channels and positions for visualization.

        Args:
            chs: List of channel names.
            positions: List of channel positions. Should be tuple of (x, y, z).
        """
        if not self.epoch_data:
            raise ValueError("No valid epoch data is generated")
        self.epoch_data.set_channels(chs, positions)

    def get_saliency_params(self) -> dict:
        """Return saliency parameters for saliiency computation.

        Raises:
            ValueError: If no valid trainer has been generated.
        """
        return self.saliency_params
    
    def set_saliency_params(self, saliency_params) -> None:
        """Set saliency parameters for saliency computation.

        Args:
            saliency_params: The saliency parameters. Nest dictionary of {'method', {'param', value}}
        """
        self.saliency_params = saliency_params
        if self.trainer:
            for training_plan_holder in self.trainer.get_training_plan_holders():
                training_plan_holder.set_saliency_params(saliency_params)

    """clean work flow
    ########################################
    1. raw/preprocessed(epoched) data
    2. training datasets (splitted)
    3. training plan (trainer)
    """
    # stage 1
    def should_clean_raw_data(self, interact: bool = True) -> bool:
        """Return whether raw data is loaded.

        Args:
            interact: Whether to raise error if raw data is loaded.
        """
        response = self.loaded_data_list or self.should_clean_datasets(interact)
        if response and interact:
            raise ValueError(
                'This step has already been done, '
                'all following data will be removed if you reset this step.\n'
                'Please clean_raw_data first.'
            )
        return response

    def clean_raw_data(self, force_update: bool = True) -> None:
        """Clean raw/preprocessed/epoched data and following steps.

        Args:
            force_update: Whether to force override and
                          clear the data of following steps.
        """
        self.clean_datasets(force_update=force_update)
        if not force_update:
            self.should_clean_raw_data(interact=True)
        self.loaded_data_list = []
        self.preprocessed_data_list = []
        self.epoch_data = None

    # stage 2
    def should_clean_datasets(self, interact: bool = True) -> bool:
        """Return whether datasets is generated.

        Args:
            interact: Whether to raise error if datasets is generated.
        """
        response = self.datasets or self.should_clean_trainer(interact)
        if response and interact:
            raise ValueError(
                'This step has already been done, '
                'all following data will be removed if you reset this step.\n'
                'Please clean_datasets first.'
            )
        return response

    def clean_datasets(self, force_update: bool = True) -> None:
        """Clean datasets and following steps.

        Args:
            force_update: Whether to force override and
                          clear the data of following steps.
        """
        self.clean_trainer(force_update=force_update)
        if not force_update:
            self.should_clean_datasets(interact=True)
        self.datasets = []

    # stage 3
    def should_clean_trainer(self, interact: bool = True) -> bool:
        """Return whether trainer is generated.

        Args:
            interact: Whether to raise error if trainer is generated.
        """
        response = self.trainer is not None
        if response and interact:
            raise ValueError(
                'This step has already been done, '
                'all following data will be removed if you reset this step.\n'
                'Please clean_trainer first.'
            )
        return response

    def clean_trainer(self, force_update: bool = True) -> None:
        """Clean trainer.

        Args:
            force_update: Whether to force override and
                          clear the data of following steps.
        """
        if not force_update:
            self.should_clean_trainer(interact=True)
        if self.trainer:
            self.trainer.clean(force_update=force_update)
        self.trainer = None
